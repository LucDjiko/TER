import os
from tqdm import tqdm
from langchain.document_loaders import SimpleDirectoryLoader
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter

data_dir = "C:/Users/Luc/Downloads/06_sfcr.zip"

pdf_loader = SimpleDirectoryLoader(data_dir)
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, length_function=len)

model_name = "sentence-transformers/all-mpnet-base-v2"
model_kwargs = {"device": "cpu"}

hf = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)

langchain_documents = []

try:
    data = pdf_loader.load()
    langchain_documents.extend(data)
except Exception as e:
    print(f"Error loading document: {e}")

print("Num documents: ", len(langchain_documents))

split_docs = text_splitter.split_documents(langchain_documents)

db = FAISS.from_documents(split_docs, embedding=hf)
